
| distributed init (rank 0): env://
number of params: 86567656
Start training for 300 epochs
Epoch: [0]  [   0/1251]  eta: 2:32:34  lr: 0.000001  loss: 7.0176 (7.0176)  time: 7.3176  data: 4.5866  max mem: 26207
Epoch: [0]  [  10/1251]  eta: 0:23:35  lr: 0.000001  loss: 7.0515 (7.0572)  time: 1.1407  data: 0.4172  max mem: 26872
Exception in thread Thread-3:
Traceback (most recent call last):
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/multiprocessing/connection.py", line 630, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Traceback (most recent call last):
  File "main.py", line 863, in <module>
    main(args)
  File "main.py", line 684, in main
    train(model, criterion, optimizer, lr_scheduler, n_parameters, device, data_loader_train, data_loader_val, dataset_val, loss_scaler, model_ema, mixup_fn, output_dir)
  File "main.py", line 789, in train
    train_stats = train_one_epoch(
  File "/home/mingyuan/lab/deit/engine.py", line 67, in train_one_epoch
    loss_scaler(loss, optimizer, clip_grad=max_norm,
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/timm/utils/cuda.py", line 46, in __call__
    self._scaler.step(optimizer)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py", line 370, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py", line 289, in _maybe_opt_step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py", line 289, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
KeyboardInterrupt