
| distributed init (rank 0): env://
number of params: 86567656
Start training for 300 epochs
Traceback (most recent call last):
  File "main.py", line 863, in <module>
    main(args)
  File "main.py", line 684, in main
    train(model, criterion, optimizer, lr_scheduler, n_parameters, device, data_loader_train, data_loader_val, dataset_val, loss_scaler, model_ema, mixup_fn, output_dir)
  File "main.py", line 789, in train
    train_stats = train_one_epoch(
  File "/home/mingyuan/lab/deit/engine.py", line 47, in train_one_epoch
    outputs = model(samples)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/timm/models/vision_transformer.py", line 281, in forward
    x = self.forward_features(x)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/timm/models/vision_transformer.py", line 275, in forward_features
    x = blk(x)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/timm/models/vision_transformer.py", line 141, in forward
    x = x + self.drop_path(self.attn(self.norm1(x)))
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mingyuan/anaconda3/envs/deit/lib/python3.8/site-packages/timm/models/vision_transformer.py", line 116, in forward
    attn = (q @ k.transpose(-2, -1)) * self.scale
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 456.00 MiB (GPU 0; 47.41 GiB total capacity; 46.29 GiB already allocated; 112.75 MiB free; 46.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF